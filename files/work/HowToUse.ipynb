{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b48f157-4635-42f0-9fba-a7cbbe5cc67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg, os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from pymongo import MongoClient\n",
    "import opendatasets as od\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8822b-263f-4cc4-88a4-0b46d49dc6be",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff870c33-1547-4526-9f6e-26e9a204be1b",
   "metadata": {},
   "source": [
    "# FOR MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9447e294-66d8-4a9f-8ba3-1fc535b1e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://admin:PassW0rd@hackathon-mongo:27017/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5672770e-9701-46e6-8afe-869186ca2535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'config', 'local']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbnames = client.list_database_names()\n",
    "dbnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19eaa139-175d-46aa-a3e1-cee26a1ae5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f73284-79c6-4aff-90ae-f6e27387114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45cd2717-1be0-4e0e-b276-21e000ec24b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['hackathon-mongo:27017'], document_class=dict, tz_aware=False, connect=True), 'test'), 'test')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c9fedd4-0bea-46b0-b9e5-d348f2374a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection = db.test\n",
    "\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "\n",
    "post = {'singer': 'Louis Armstrong',\n",
    "        \"song\": \"What a wonderful world\",\n",
    "        \"tags\":[\"jazz\", \"blues\"],\n",
    "        \"date\": datetime.now()\n",
    "}\n",
    "\n",
    "post_id = collection.insert_one(post).inserted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2c6a3de-a60d-4110-b314-0812d8d5515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first post id: 67f087ba5af131d8fa065609\n",
      "Our first post: {'singer': 'Louis Armstrong', 'song': 'What a wonderful world', 'tags': ['jazz', 'blues'], 'date': datetime.datetime(2025, 4, 5, 1, 30, 34, 382886), '_id': ObjectId('67f087ba5af131d8fa065609')}\n"
     ]
    }
   ],
   "source": [
    "print('Our first post id: {0}'.format(post_id))\n",
    "print('Our first post: {0}'.format(post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29b3f457-ab62-437c-92f0-370fb5542064",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18101d64-cab1-4518-bab5-d401beda8dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666cf13-1cb9-4fb7-8d57-303b64728e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3df06051-54c2-4f8f-b274-d11b49c7627a",
   "metadata": {},
   "source": [
    "# Download dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25822a0f-515d-4398-8916-1bec336e6a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/ibrahimfateen/wound-classification\n"
     ]
    }
   ],
   "source": [
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/ibrahimfateen/wound-classification/data\", './Downloads')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba34d9-f2de-40a2-8526-fa03f44a6af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709c123-e4a6-4ee4-ad55-34a6ed8fb1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50230b03-e4e8-44a0-b5dc-695040cf6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740461ad-995d-463b-a706-a2f5ab1f9927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4110e62-4db1-4141-9d16-a797f57781d5",
   "metadata": {},
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8fe8e3-9379-4a04-afff-e708a4be6495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2940 images belonging to 10 classes.\n",
      "Found 2940 images belonging to 10 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - accuracy: 0.1703 - loss: 2.5501 - val_accuracy: 0.2520 - val_loss: 2.0054\n",
      "Epoch 2/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - accuracy: 0.2604 - loss: 2.0127 - val_accuracy: 0.3707 - val_loss: 1.7086\n",
      "Epoch 3/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - accuracy: 0.3088 - loss: 1.8773 - val_accuracy: 0.4303 - val_loss: 1.6085\n",
      "Epoch 4/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.3557 - loss: 1.8014 - val_accuracy: 0.4677 - val_loss: 1.5333\n",
      "Epoch 5/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - accuracy: 0.3725 - loss: 1.7521 - val_accuracy: 0.4857 - val_loss: 1.5175\n",
      "Epoch 6/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 215ms/step - accuracy: 0.3869 - loss: 1.7078 - val_accuracy: 0.4833 - val_loss: 1.4626\n",
      "Epoch 7/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 215ms/step - accuracy: 0.4155 - loss: 1.6601 - val_accuracy: 0.5177 - val_loss: 1.4532\n",
      "Epoch 8/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - accuracy: 0.4062 - loss: 1.6156 - val_accuracy: 0.5514 - val_loss: 1.3580\n",
      "Epoch 9/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 230ms/step - accuracy: 0.4432 - loss: 1.5580 - val_accuracy: 0.5466 - val_loss: 1.3541\n",
      "Epoch 10/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 229ms/step - accuracy: 0.4533 - loss: 1.5617 - val_accuracy: 0.5503 - val_loss: 1.2521\n",
      "Epoch 11/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - accuracy: 0.4740 - loss: 1.4958 - val_accuracy: 0.5592 - val_loss: 1.2879\n",
      "Epoch 12/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 229ms/step - accuracy: 0.4703 - loss: 1.4728 - val_accuracy: 0.5197 - val_loss: 1.3698\n",
      "Epoch 13/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - accuracy: 0.4654 - loss: 1.4417 - val_accuracy: 0.5833 - val_loss: 1.1630\n",
      "Epoch 14/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - accuracy: 0.4819 - loss: 1.4493 - val_accuracy: 0.5816 - val_loss: 1.1895\n",
      "Epoch 15/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - accuracy: 0.4794 - loss: 1.4333 - val_accuracy: 0.5711 - val_loss: 1.2146\n",
      "Epoch 16/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - accuracy: 0.4965 - loss: 1.4102 - val_accuracy: 0.5929 - val_loss: 1.1407\n",
      "Epoch 17/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 233ms/step - accuracy: 0.4982 - loss: 1.3971 - val_accuracy: 0.5779 - val_loss: 1.1470\n",
      "Epoch 18/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - accuracy: 0.5154 - loss: 1.4051 - val_accuracy: 0.6000 - val_loss: 1.1274\n",
      "Epoch 19/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - accuracy: 0.5435 - loss: 1.3463 - val_accuracy: 0.6364 - val_loss: 1.0399\n",
      "Epoch 20/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - accuracy: 0.5383 - loss: 1.3051 - val_accuracy: 0.6456 - val_loss: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved as 'wound_classification_model.h5'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "dataset_path = \"./Downloads/wound-classification/Wound_dataset copy\"  # Replace with the actual path to your dataset\n",
    "# train_dir = os.path.join(dataset_path, \"train\")\n",
    "# val_dir = os.path.join(dataset_path, \"val\")\n",
    "train_dir = dataset_path  # Since images are already categorized in folders, use the root dataset path\n",
    "val_dir = dataset_path  # Use the same path for validation if no separate validation folder exists\n",
    "\n",
    "\n",
    "# Image preprocessing\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "epochs = 20\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"wound_classification_model.h5\")\n",
    "\n",
    "print(\"Model training complete and saved as 'wound_classification_model.h5'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243667e-a755-46cc-b499-9572743ec83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d77270-fd23-4827-b20e-f514e38a579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential_1 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Identify the layer name or index for embeddings (e.g., 'flatten' layer)\u001b[39;00m\n\u001b[32m     11\u001b[39m embedding_layer_name = \u001b[33m\"\u001b[39m\u001b[33mflatten\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Replace with the actual name of the layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m embedding_model = Model(inputs=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m, outputs=model.get_layer(embedding_layer_name).output)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Example: Generate embeddings for a batch of images\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Assuming `image_batch` is a batch of preprocessed images\u001b[39;00m\n\u001b[32m     16\u001b[39m image_batch = np.random.rand(\u001b[32m10\u001b[39m, \u001b[32m150\u001b[39m, \u001b[32m150\u001b[39m, \u001b[32m3\u001b[39m)  \u001b[38;5;66;03m# Replace with actual preprocessed images\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/keras/src/ops/operation.py:276\u001b[39m, in \u001b[36mOperation.input\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[32m    269\u001b[39m \n\u001b[32m    270\u001b[39m \u001b[33;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_tensors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/keras/src/ops/operation.py:307\u001b[39m, in \u001b[36mOperation._get_node_attribute_at_index\u001b[39m\u001b[34m(self, node_index, attr, attr_name)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[32m    292\u001b[39m \n\u001b[32m    293\u001b[39m \u001b[33;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    304\u001b[39m \u001b[33;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inbound_nodes:\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    308\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has never been called \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    309\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    310\u001b[39m     )\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes) > node_index:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    313\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at node \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    314\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but the operation has only \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    315\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m inbound nodes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    316\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: The layer sequential_1 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"wound_classification_model.h5\")\n",
    "\n",
    "# Define the input shape explicitly\n",
    "input_shape = (150, 150, 3)  # Replace with your model's input shape\n",
    "\n",
    "# Identify the layer name or index for embeddings (e.g., 'flatten' layer)\n",
    "embedding_layer_name = \"flatten\"  # Replace with the actual name of the layer\n",
    "embedding_model = Model(inputs=model.input, outputs=model.get_layer(embedding_layer_name).output)\n",
    "\n",
    "# Example: Generate embeddings for a batch of images\n",
    "# Assuming `image_batch` is a batch of preprocessed images\n",
    "image_batch = np.random.rand(10, 150, 150, 3)  # Replace with actual preprocessed images\n",
    "embeddings = embedding_model.predict(image_batch)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefae452-5462-41df-bf80-5a4073c0aa9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52759de7-e251-49a7-9c25-afd98a023362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53110e79-99de-4e1e-b694-779429abe208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2364b32-7a12-4289-b0e6-6bb44b8ff529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a9a93-d2c6-4f11-9599-60f2255da074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05b808-f288-464c-8e97-68bcc72cdacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7f837-6423-40c3-9006-65824359cc82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be961528-8ba1-48ba-ae38-75be0606cc74",
   "metadata": {},
   "source": [
    "---\n",
    "# APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900cd2b-cd86-42bc-8b63-bf051d136c39",
   "metadata": {},
   "source": [
    "### Call API for flask app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63dedb4c-816d-4f88-92d7-2a5077e89521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New API data: MongoDB connected successfully!\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import json\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "try:\n",
    "    response = http.request('GET', 'http://hackathon-flask-app:5010/api/test')\n",
    "\n",
    "    if response.status == 200:\n",
    "        # data = json.loads(response.data.decode('utf-8'))\n",
    "        \n",
    "        print(f\"New API data: {response.data.decode('utf-8')}\")\n",
    "    else:\n",
    "        print(f\"An error occurred: {response.status}\")\n",
    "except urllib3.exceptions.HTTPError as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b80eb-a8e6-411d-9d77-3e3c41e8ed6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4205d8-86dd-42bd-b1c8-e77f9bac1662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70d2fa-d56b-4c68-b6dd-ef0a4d8e9c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
